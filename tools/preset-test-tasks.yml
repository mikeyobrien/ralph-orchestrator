# Preset Test Tasks
# Maps each preset to a canonical test task for benchmarking

test_tasks:
  hatless-baseline: |
    Build a mini CLI calculator in Rust with the following requirements:
    1. Create the module at `.eval-sandbox/baseline/calculator.rs`
    2. Implement: add, subtract, multiply, divide operations
    3. Handle division by zero gracefully (return Result type)
    4. Write comprehensive tests for all operations including edge cases
    5. Verify all tests pass before completing

    Work iteratively: plan, implement core ops, add error handling, write tests, verify.

  tdd-red-green: |
    Using TDD, implement an `is_palindrome(s: &str) -> bool` function.
    Create the test file at `.eval-sandbox/tdd/palindrome_test.rs`.
    Follow the red-green-refactor cycle strictly.

  adversarial-review: |
    Review this user input handler for security vulnerabilities:
    ```rust
    fn handle_input(user_input: &str) -> String {
        let cmd = format!("echo {}", user_input);
        std::process::Command::new("sh").arg("-c").arg(&cmd).output()
    }
    ```
    Document findings in `.eval-sandbox/security/review.md`.

  socratic-learning: |
    Help me understand how the HatRegistry works in this codebase.
    Specifically: How does it route events to the correct hat?
    Document your understanding in `.eval-sandbox/learning/hat-registry.md`.

  spec-driven: |
    Specify and implement a `truncate(s: &str, max_len: usize) -> String` function.
    Requirements: handles unicode, adds "..." if truncated, never exceeds max_len.
    Work in `.eval-sandbox/spec-driven/`.

  mob-programming: |
    As a mob, implement a generic Stack<T> with push, pop, peek, and is_empty.
    Work in `.eval-sandbox/mob/stack.rs`.

  scientific-method: |
    Debug why this test might fail intermittently:
    ```rust
    #[test]
    fn test_counter() {
        let counter = Arc::new(AtomicUsize::new(0));
        let handles: Vec<_> = (0..10).map(|_| {
            let c = counter.clone();
            thread::spawn(move || c.fetch_add(1, Ordering::Relaxed))
        }).collect();
        for h in handles { h.join().unwrap(); }
        assert_eq!(counter.load(Ordering::Relaxed), 10);
    }
    ```
    Document your investigation in `.eval-sandbox/debug/counter.md`.

  code-archaeology: |
    Investigate the history and evolution of `crates/ralph-core/src/config.rs`.
    Document: Why is it so large? What were the major changes? What gotchas exist?
    Save findings to `.eval-sandbox/archaeology/config-history.md`.

  performance-optimization: |
    Profile the hat matching logic in HatRegistry::get_for_topic().
    Suggest and implement ONE optimization.
    Document baseline and improvement in `.eval-sandbox/perf/optimization.md`.

  api-design: |
    Design a Cache<K, V> trait with get, set, delete, and clear methods.
    Include TTL support. Work in `.eval-sandbox/api/cache.rs`.
    Focus on ergonomics from the consumer's perspective.

  documentation-first: |
    Write documentation for a RateLimiter struct BEFORE implementing it.
    Include: usage examples, configuration options, error handling.
    Work in `.eval-sandbox/docs/rate_limiter.md` then implement.

  incident-response: |
    Simulate responding to: "CI tests are failing on main branch since last deploy."
    Use the incident response workflow to diagnose and propose a fix.
    Document in `.eval-sandbox/incident/response.md`.

  migration-safety: |
    Plan a migration from Ralph v1 flat config format to v2 nested format.
    Use the expand-contract pattern. Document the plan in `.eval-sandbox/migration/plan.md`.

# Complexity ratings for time budgeting
# NOTE: Ratings based on actual iteration counts and per-iteration times observed
# Multi-hat presets with exploration tend to run longer (~75-90s/iteration)
complexity:
  hatless-baseline: medium
  tdd-red-green: simple
  adversarial-review: medium
  socratic-learning: medium     # Up to 9 iterations with exploration - was incorrectly simple
  spec-driven: medium
  mob-programming: medium       # Multi-role preset runs longer - was incorrectly simple
  scientific-method: medium
  code-archaeology: complex     # Git history exploration runs slow - was incorrectly medium
  performance-optimization: complex
  api-design: medium
  documentation-first: medium
  incident-response: medium
  migration-safety: complex

# Expected iteration ranges
expected_iterations:
  hatless-baseline: [3, 5]
  tdd-red-green: [3, 6]
  adversarial-review: [3, 5]
  socratic-learning: [3, 9]
  spec-driven: [4, 8]
  mob-programming: [3, 6]
  scientific-method: [4, 8]
  code-archaeology: [4, 5]
  performance-optimization: [4, 8]
  api-design: [4, 6]
  documentation-first: [4, 6]
  incident-response: [4, 5]
  migration-safety: [4, 5]

# Timeout per preset (seconds)
# Based on observed per-iteration times:
#   - Simple presets: ~45-60s/iteration
#   - Multi-hat presets: ~75-90s/iteration (context loading, exploration)
#   - Complex presets: ~90-120s/iteration (git history, profiling)
# Adding 50% buffer for API latency variance
#   simple (3-6 iters): 6 × 75s = 450s → use 450s
#   medium (4-9 iters): 9 × 90s = 810s → use 900s
#   complex (4-8 iters): 8 × 120s = 960s → use 1200s
timeouts:
  simple: 450
  medium: 900
  complex: 1200
